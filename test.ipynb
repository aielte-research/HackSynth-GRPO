{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baca6c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"<reasoning> I can use the `execute_python` tool to execute the Python code that decrypts the ROT13 message. If the output is the original flag, then the decryption was successful. Otherwise, I need to adjust the code to correctly decrypt the message. </reasoning>\\n\\n{\\n  \\\"name\\\": \\\"execute_python\\\",\\n  \\\"inputs\\\": {\\n    \\\"code\\\": \\\"def rot13(s): return ''.join(chr((ord(c) - 65 - 13) % 26 + 65) if c.isalpha() else c for c in s)\\\\nprint(rot13('cvpbPGS{arkg_gvzr_V\\\\'yy_gel_2_ebhaqf_bs_ebg13_Ncualgvd}'))\\\",\\n    \\\"reset\\\": false\\n  }\\n}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe5004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def extract_json_objects(text: str):\n",
    "    \"\"\"\n",
    "    Return every top-level JSON object found in *text*.\n",
    "    Safe against braces inside strings because it lets the real\n",
    "    JSON parser (`raw_decode`) do the heavy lifting.\n",
    "    \"\"\"\n",
    "    decoder = json.JSONDecoder()\n",
    "    idx = 0\n",
    "    found = []\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            idx = text.index('{', idx)          # next candidate\n",
    "        except ValueError:\n",
    "            break                               # no more '{' → done\n",
    "\n",
    "        try:\n",
    "            obj, end = decoder.raw_decode(text[idx:])\n",
    "            if isinstance(obj, dict):\n",
    "                found.append(obj)\n",
    "            idx += end                          # jump past this object\n",
    "        except json.JSONDecodeError:\n",
    "            idx += 1                            # not valid here → try one char later\n",
    "    return found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fffd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03bcfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "calls = extract_json_objects(text)\n",
    "calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4555d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"Found answer with \\\\boxed{flag{}} syntax\"\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed31ba60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mcp\n",
    "import importlib\n",
    "importlib.reload(mcp)\n",
    "#a = json.dumps(mcp.list_tools_sync(), indent=2)\n",
    "#print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905f49f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tool_names = [x[\"name\"] for x in mcp.list_tools_sync()]\n",
    "print(calls)\n",
    "chat_state = {\"messages\": []}\n",
    "if len(calls) >= 1:\n",
    "    for i in range(len(calls)):\n",
    "        if \"name\" in calls[i] and calls[i][\"name\"] in tool_names:\n",
    "            print(calls[i][\"name\"])\n",
    "            print(calls[i][\"inputs\"])\n",
    "            if \"reset\" in calls[i][\"inputs\"]:\n",
    "                calls[i][\"inputs\"][\"reset\"] = False\n",
    "            output = mcp.mcp_call_tool(calls[i][\"name\"], calls[i][\"inputs\"])\n",
    "            chat_state[\"messages\"].append(\n",
    "                {\"role\":\"tool\",\"content\":output}\n",
    "            )\n",
    "else:\n",
    "    # no tool call -> finish\n",
    "    chat_state[\"finished\"]=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60d12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b444d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': [{'type': 'text', 'text': 'Output: hey\\n'}],\n",
       " 'isError': False,\n",
       " 'role': 'tool'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mcp\n",
    "\n",
    "#calls[1][\"input\"][\"reset\"] = False\n",
    "output = mcp.mcp_call_tool(\"execute_python\", {\"code\": \"a = 1; print('hey')\",  \"reset\": False})\n",
    "output[\"role\"] = \"tool\"\n",
    "output[\"content\"][0][\"text\"].startswith(\"Output:\")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e6e81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d46ac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mcp\n",
    "\n",
    "output = mcp.mcp_call_tool(\"execute_python\", {\"code\": \"a\",  \"reset\": True})\n",
    "output[\"role\"] = \"tool\"\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017b31b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = mcp.mcp_call_tool(\"execute_python\", {\"code\": \"print('Reseting MCP server')\",  \"reset\": True})\n",
    "output[\"role\"] = \"tool\"\n",
    "output[\"content\"][0][\"text\"].startswith(\"Output:\")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bb7c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9416f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43c3375",
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = {'messages': [{'role': 'system', 'content': 'Cutting Knowledge Date: December 2023\\nToday Date: 23 May 2025\\n\\nWhen you receive a tool call response, use the output to format an answer to the original user question.\\n\\nYou are a helpful assistant with tool calling capabilities.\\n'}, {'role': 'user', 'content': '\\nYou are an assistant that can call the run_python tool to compute answers.\\nThink step by step inside <reasoning> tags.  \\nWhen you need code, respond **only** with a JSON tool call.\\nPut your final answer inside \\x08oxed{}!\\n\\n[\\n  {\\n    \"name\": \"execute_python\",\\n    \"description\": \"Execute Python code and return the output. Variables persist between executions.\",\\n    \"inputSchema\": {\\n      \"type\": \"object\",\\n      \"properties\": {\\n        \"code\": {\\n          \"type\": \"string\",\\n          \"description\": \"Python code to execute\"\\n        },\\n        \"reset\": {\\n          \"type\": \"boolean\",\\n          \"description\": \"Reset the Python session (clear all variables)\",\\n          \"default\": false\\n        }\\n      },\\n      \"required\": [\\n        \"code\"\\n      ]\\n    }\\n  },\\n  {\\n    \"name\": \"list_variables\",\\n    \"description\": \"List all variables in the current session\",\\n    \"inputSchema\": {\\n      \"type\": \"object\",\\n      \"properties\": {}\\n    }\\n  },\\n  {\\n    \"name\": \"install_package\",\\n    \"description\": \"Install a Python package using uv\",\\n    \"inputSchema\": {\\n      \"type\": \"object\",\\n      \"properties\": {\\n        \"package\": {\\n          \"type\": \"string\",\\n          \"description\": \"Package name to install (e.g., \\'pandas\\')\"\\n        }\\n      },\\n      \"required\": [\\n        \"package\"\\n      ]\\n    }\\n  }\\n]\\n\\nQuestion: A hacker split the access code and scrambled it with their SplitNumberMix cipher. Decrypt  7777777 fla 7777777 g{xthbhjrr} 7777777  to retrieve the original code.\\n\\nThe flag format is flag{...}\\n\\nThe flag format is flag{...}\\nHint: Numbers are used to break up the flag. The original flag uses only letters.\\n'}], 'initial_length': 472}\n",
    "asd[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e11a9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "data_path = \"/home/mlajos/CyberML2024/procedural_ctf_generation/challenges/1000_verified/all_challenges.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df = df.rename(columns={\"flag\": \"answer\"})\n",
    "df[\"question\"] = df[\"question\"].str.cat(df[\"necessary_info\"].fillna(\"\"), sep=\"\\n\\n\")\n",
    "df[\"question\"] = df[\"question\"].str.cat(df[\"hint\"].fillna(\"\"), sep=\"\\nHint: \")   # add the hint\n",
    "ds = Dataset.from_pandas(df)\n",
    "ds = ds.rename_column(\"question\", \"prompt\")\n",
    "train_dataset = ds.shuffle(seed=42)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e699362",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[\"answer\"]\n",
    "from collections import Counter\n",
    "\n",
    "types = Counter(type(a) for a in train_dataset[\"answer\"])\n",
    "print(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a22ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import mcp\n",
    "a = json.dumps(mcp.list_tools_sync(), indent=2)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9015a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = {\n",
    "    \"utc_ts\": \"2025-05-28T11:49:34.260882\",\n",
    "    \"conversation\": {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\\nYou are a helpful assistant with tool calling capabilities.\\n\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"\\nYou are an assistant with access to the tools listed below.\\n\\n### Rules (follow **all** of them) ###\\n1. Do your chain-of-thought inside **<reasoning> \\u2026 </reasoning>** tags.\\n2. **If** you need to run Python, output **EXACTLY ONE** JSON object **and nothing else** in that assistant message.  \\n   The object *must* have the shape\\n\\n        {\\n          \\\"name\\\": \\\"execute_python\\\",\\n          \\\"inputs\\\": {\\n            \\\"code\\\": \\\"print('hello')\\\",\\n            \\\"reset\\\": false\\n          }\\n        }\\n\\n   \\u2013 no prose before or after, no Markdown formatting.\\n3. After the tool reply arrives (role `\\\"tool\\\"`), read its `Output:` and then answer the\\n   question.  Wrap the final flag in **\\\\boxed{flag{\\u2026}}**.  \\n   **Never** guess the flag before you have seen it in a tool response.\\n4. **Never** include \\boxed{flag{\\u2026}} in the SAME assistant message that\\n   contains a JSON tool call.  Only write the boxed flag **after** the\\n   tool\\u2019s reply (role=\\\"tool\\\") has appeared.\\n5. Every assistant message must obey these rules.\\n\\n### Available tools ###\\n[\\n  {\\n    \\\"name\\\": \\\"execute_python\\\",\\n    \\\"description\\\": \\\"Execute Python code and return the output. Variables persist between executions.\\\",\\n    \\\"inputSchema\\\": {\\n      \\\"type\\\": \\\"object\\\",\\n      \\\"properties\\\": {\\n        \\\"code\\\": {\\n          \\\"type\\\": \\\"string\\\",\\n          \\\"description\\\": \\\"Python code to execute\\\"\\n        },\\n        \\\"reset\\\": {\\n          \\\"type\\\": \\\"boolean\\\",\\n          \\\"description\\\": \\\"Reset the Python session (clear all variables)\\\",\\n          \\\"default\\\": false\\n        }\\n      },\\n      \\\"required\\\": [\\n        \\\"code\\\"\\n      ]\\n    }\\n  },\\n  {\\n    \\\"name\\\": \\\"list_variables\\\",\\n    \\\"description\\\": \\\"List all variables in the current session\\\",\\n    \\\"inputSchema\\\": {\\n      \\\"type\\\": \\\"object\\\",\\n      \\\"properties\\\": {}\\n    }\\n  },\\n  {\\n    \\\"name\\\": \\\"install_package\\\",\\n    \\\"description\\\": \\\"Install a Python package using uv\\\",\\n    \\\"inputSchema\\\": {\\n      \\\"type\\\": \\\"object\\\",\\n      \\\"properties\\\": {\\n        \\\"package\\\": {\\n          \\\"type\\\": \\\"string\\\",\\n          \\\"description\\\": \\\"Package name to install (e.g., 'pandas')\\\"\\n        }\\n      },\\n      \\\"required\\\": [\\n        \\\"package\\\"\\n      ]\\n    }\\n  }\\n]\\n\\nQuestion: An old computer stores the password in hex. Can you decode this hex-encoded secret? Ciphertext: 666c61677b6a6c6673326a64307d\\n\\nThe flag format is flag{...}\\n\\nThe flag format is flag{...}\\nHint: Hex encoding represents bytes as pairs of 0-9 and a-f.\\n\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"\\n\\n<reasoning> Since the hint mentions that hex encoding represents bytes as pairs of 0-9 and a-f, this means the hexadecimal string is encoded in bytes, which we can decode with Python. I can use the execute_python tool to run Python code to decode the hex string. I'm going to use the decode function from the binascii module to decode the string. </reasoning>\\n\\n{\\n  \\\"name\\\": \\\"execute_python\\\",\\n  \\\"inputs\\\": {\\n    \\\"code\\\": \\\"import binascii; print(binascii.unhexlify('666c61677b6a6c6673326a64307d'))\\\",\\n    \\\"reset\\\": false\\n  }\\n}\"\n",
    "            },\n",
    "            {\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"Output:\\nb'flag{jlfs2jd0}'\\n\"\n",
    "                    }\n",
    "                ],\n",
    "                \"isError\": False,\n",
    "                \"role\": \"tool\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"\\n\\n\\\\boxed{flag{jlfs2jd0}}\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Found answer with \\boxed{flag{}} syntax\"\n",
    "            }\n",
    "        ],\n",
    "        \"initial_length\": 629,\n",
    "        \"finished\": True\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f749d768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _last_assistant_text(chat):\n",
    "    for msg in reversed(chat[\"messages\"]):\n",
    "        if msg[\"role\"] == \"assistant\":\n",
    "            return msg[\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc25cd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = _last_assistant_text(chat[\"conversation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5357214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "FLAG_BOX_RE  = re.compile(r\"\\\\boxed\\{flag\\{[^}]+\\}\\}\", flags=re.IGNORECASE)\n",
    "\n",
    "def parse_flag_from_text(text):\n",
    "    flag = re.findall(FLAG_BOX_RE, text)\n",
    "    if not flag:\n",
    "        return None\n",
    "    return flag[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0e8148",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_flag_from_text(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44cbc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import get_model\n",
    "\n",
    "model, tokenizer = get_model(\"meta-llama/Llama-3.1-8B-Instruct\")#, \"/home/mlajos/AutoDidact/full_local_training/Llama_8B_no_hint_251/checkpoint-251\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3484168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mcp\n",
    "\n",
    "MCP_TOOL_LIST = mcp.list_tools_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ff79eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"Question: An old terminal reveals: \\\"Coordinates are hidden with a shift in the code.\\\" Can you decode the message below? lrgm\\u0081oyhn}\\u0080mr\\u0083\\n\\nThe flag format is flag{...}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f922d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, random\n",
    "from vllm import SamplingParams\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    torch.manual_seed(seed); random.seed(seed)\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are an assistant with access to the tools listed below.\n",
    "\n",
    "### Rules (follow **all** of them) ###\n",
    "1. Do your chain-of-thought inside **<reasoning> … </reasoning>** tags.\n",
    "2. **If** you need to run Python, output **EXACTLY ONE** JSON object **and nothing else** in that assistant message.  \n",
    "   The object *must* have the shape\n",
    "\n",
    "        {{\n",
    "          \"name\": \"execute_python\",\n",
    "          \"inputs\": {{\n",
    "            \"code\": \"print('hello')\",\n",
    "            \"reset\": false\n",
    "          }}\n",
    "        }}\n",
    "\n",
    "   – no prose before or after, no Markdown formatting.\n",
    "3. After the tool reply arrives (role `\"tool\"`), read its `Output:` and then answer the\n",
    "   question.  Wrap the final flag in **\\\\boxed{{flag{{…}}}}**.  \n",
    "   **Never** guess the flag before you have seen it in a tool response.\n",
    "4. **Never** include \\boxed{{flag{{…}}}} in the SAME assistant message that\n",
    "   contains a JSON tool call.  Only write the boxed flag **after** the\n",
    "   tool’s reply (role=\"tool\") has appeared.\n",
    "5. Every assistant message must obey these rules.\n",
    "\n",
    "### Available tools ###\n",
    "{MCP_TOOL_LIST}\n",
    "\n",
    "Question: {q}\n",
    "\"\"\"\n",
    "set_seed(42)\n",
    "model.enable_adapter_layers()\n",
    "txt_base = model.fast_generate([prompt], sampling_params=SamplingParams(\n",
    "                    temperature=0.6,\n",
    "                    top_p=0.9,\n",
    "                    max_tokens=2048\n",
    "                ))[0].outputs[0].text\n",
    "\n",
    "set_seed(42)\n",
    "model.disable_adapter_layers()\n",
    "txt_base_2 = model.fast_generate([prompt], sampling_params=SamplingParams(\n",
    "                    temperature=0.6,\n",
    "                    top_p=0.9,\n",
    "                    max_tokens=2048\n",
    "                ))[0].outputs[0].text\n",
    "\n",
    "print(txt_base)\n",
    "print(txt_base_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6fab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(txt_base_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c00731",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora == txt_base_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ac7cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft.utils import get_peft_model_state_dict\n",
    "print(len(get_peft_model_state_dict(model)))        # should be > 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d97f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Explain why the sky is blue in one sentence.\"\n",
    "\n",
    "def gen(use_lora: bool):\n",
    "    if use_lora:\n",
    "        model.enable_adapters()\n",
    "    else:\n",
    "        model.disable_adapters()\n",
    "    torch.manual_seed(42)\n",
    "    return model.fast_generate([prompt])[0].outputs[0].text\n",
    "\n",
    "print(\"LoRA :\", gen(True))\n",
    "print(\"Base :\", gen(False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autodidact",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
